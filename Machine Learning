
"""

from sklearn.linear_model import LinearRegression

# Dados de exemplo
X = [[1], [2], [3], [4]]  # entradas
y = [2, 4, 6, 8]          # saídas

# Criar e treinar o modelo
modelo = LinearRegression()
modelo.fit(X, y)

# Fazer previsão
print(modelo.predict([[5]]))

"""

#----------------------------------------------------------------------------------------------------------

"""
from sklearn.datasets import load_diabetes
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# 1. Carregar dataset
X, y = load_diabetes(return_X_y=True)

# 2. Separar treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Treinar modelo
modelo = LinearRegression()
modelo.fit(X_train, y_train)

# 4. Avaliar modelo
y_pred = modelo.predict(X_test)
print("Erro quadrático médio:", mean_squared_error(y_test, y_pred))

"""

#----------------------------------------------------------------------------------------------------------

"""
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# 1. Carregar dataset
X, y = load_iris(return_X_y=True)

# 2. Separar treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Treinar modelo (classificação)
modelo = LogisticRegression(max_iter=200)
modelo.fit(X_train, y_train)

# 4. Avaliar modelo
y_pred = modelo.predict(X_test)
print("Acurácia:", accuracy_score(y_test, y_pred))

"""

#----------------------------------------------------------------------------------------------------------

"""
import matplotlib.pyplot as plt
from sklearn.datasets import load_diabetes
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# 1. Carregar dataset
X, y = load_diabetes(return_X_y=True)

# Para simplificar, usar só 1 feature (coluna 0)
X = X[:, [0]]

# 2. Separar treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Treinar modelo
modelo = LinearRegression()
modelo.fit(X_train, y_train)

# 4. Plotar dados reais (pontos) e linha do modelo
plt.scatter(X_test, y_test, color="blue", label="Dados reais")
plt.plot(X_test, modelo.predict(X_test), color="red", linewidth=2, label="Previsão")
plt.legend()
plt.xlabel("Feature (idade normalizada)")
plt.ylabel("Alvo (medida médica)")
plt.title("Regressão Linear - Diabetes")
plt.show()

"""

#----------------------------------------------------------------------------------------------------------

"""
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# 1. Carregar dataset
iris = load_iris()
X = iris.data[:, :2]  # pegar apenas 2 features (sépalas)
y = iris.target

# 2. Separar treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Treinar modelo
modelo = LogisticRegression(max_iter=200)
modelo.fit(X_train, y_train)

# 4. Plotar pontos coloridos
plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.cm.Set1, edgecolor="k")
plt.xlabel("Comprimento da sépala")
plt.ylabel("Largura da sépala")
plt.title("Classificação Iris (2 features)")
plt.show()

"""

#----------------------------------------------------------------------------------------------------------

"""
from sklearn.datasets import load_diabetes
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# 1. Carregar dataset
X, y = load_diabetes(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Treinar modelo
modelo = LinearRegression()
modelo.fit(X_train, y_train)

# 3. Avaliar com várias métricas
y_pred = modelo.predict(X_test)
print("MSE:", mean_squared_error(y_test, y_pred))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("R²:", r2_score(y_test, y_pred))
"""

#----------------------------------------------------------------------------------------------------------

"""
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# 1. Carregar dataset
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Treinar modelo
modelo = LogisticRegression(max_iter=200)
modelo.fit(X_train, y_train)

# 3. Avaliar com várias métricas
y_pred = modelo.predict(X_test)
print("Matriz de Confusão:\n", confusion_matrix(y_test, y_pred))
print("\nRelatório de Classificação:\n", classification_report(y_test, y_pred))

"""

#----------------------------------------------------------------------------------------------------------

"""

#bibliotecas

from sklearn.datasets import load_breast_cancer
from sklearn.linear_model import LogisticRegression #modelo
from sklearn.model_selection import train_test_split #treino e teste
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report #modelos usados para resultados

#1 carregar dataset
X, y = load_breast_cancer(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)

#2 treinar modelo
modelo = LogisticRegression()
modelo.fit(X_train, y_train)

#3 acuracia
y_pred = modelo.predict(X_test)
print("\nAcuracia:", accuracy_score(y_test, y_pred))

#Outras metricas
print("\nPrecisao: ", precision_score(y_test, y_pred))
print("\nRecall: ", recall_score(y_test, y_pred))
print("\nF1: ", f1_score(y_test, y_pred))

print("\nMatriz de Confusao: " "\n", confusion_matrix(y_test, y_pred))
print("\nRelatorio de classificação: " "\n", classification_report(y_test, y_pred))

"""


#----------------------------------------------------------------------------------------------------------

import torch                                  #é a base do PyTorch, lida com tensores (como arrays do NumPy, mas com GPU).
import torch.nn as nn                         #tem blocos prontos para redes neurais (camadas, funções de ativação).
import torch.optim as optim                   #otimizadores (Adam, SGD).
import torchvision                            #datasets e transformações de imagens.
import torchvision.transforms as transforms

#Datasets
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])   # converte imagem para tensor (PyTorch entende tensores, não imagens) ( "transform.Normalize" normaliza os pixels (-1 a 1))

trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)      #dataset de dígitos escritos à mão (60.000 treino, 10.000 teste, imagens 28x28).
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)                          #cria "lotes" (batch) de 64 imagens de cada vez. Isso economiza memória e acelera o treino.

testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)

#Modelo
class Net(nn.Module):                                                                                   #- Define uma classe chamada Net, que herda de nn.Module, a base para todas as redes neurais em PyTorch.
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(28*28, 128)                                                                # - Primeira camada totalmente conectada (fully connected), que recebe uma imagem de 28x28 pixels (784 entradas) e transforma em 128 neurônios.
        self.fc2 = nn.Linear(128, 10)   #128 → 10 neurônios (para os dígitos de 0 a 9).                 #- Segunda camada, que pega os 128 neurônios e gera 10 saídas, correspondendo aos dígitos de 0 a 9.

    def forward(self, x):
        x = x.view(-1, 28*28)                                                                           #- Redimensiona o tensor de entrada (imagem) para um vetor de 784 elementos. O -1 deixa o PyTorch calcular automaticamente o tamanho do batch.
        x = torch.relu(self.fc1(x))                                                                     #Função de ativação ReLU (Rectified Linear Unit) deixa a rede aprender relações não-lineares.
        x = self.fc2(x)                                                                                 #Passa pela segunda camada, que gera os logits (valores brutos antes do softmax).
        return x                                                                                        #- Retorna os logits, que depois serão usados para calcular a probabilidade de cada classe.
                                                                                                        #Em poucas palavras Essa rede é ideal para tarefas como: - Classificar imagens de dígitos manuscritos (ex: MNIST) - Reconhecer padrões simples em imagens pequenas


#Loss e Otimizador
model = Net()
criterion =  nn.CrossEntropyLoss()                          # mede o erro entre previsão e resposta correta   #CrossEntropyLoss = padrão para classificação multi-classe.
optimizer = optim.Adam(model.parameters(), lr=0.001)        # ajusta pesos da rede                            #Adam = otimizador que atualiza os pesos automaticamente.
                                                            #lr=0.001 = taxa de aprendizado (passo que a rede dá para corrigir erros).


#Treino
for epoch in range(5):                                      # 5 passagens completas pelo dataset    #Epoch = uma vez que a rede vê todos os dados de treino.
    for images, labels in trainloader:                      # pega lotes de imagens e rótulos
        optimizer.zero_grad()                               # zera gradientes acumulados
        outputs = model(images)                             # faz previsão                          #Forward pass = rede faz previsão.
        loss = criterion(outputs, labels)                   # calcula erro                          #Loss = mede o quão errado a rede está.
        loss.backward()                                     # retropropagação (backpropagation)     #Backward pass (loss.backward()) = calcula os gradientes (quanto cada peso errou).
        optimizer.step()                                    # atualiza pesos                        #Optimizer.step() = ajusta os pesos para errar menos na próxima vez.


#Avaliação
correct, total = 0, 0                                       #- Inicializa dois contadores: - correct: número de previsões corretas - total: número total de amostras avaliadas
with torch.no_grad():                                       # Evita que o PyTorch calcule gradientes durante a avaliação, economizando memória e processamento. Isso é padrão quando não estamos treinando.
    for images, labels in testloader:
        outputs = model(images)                             #Passa as imagens pela rede () e obtém os logits (valores brutos antes do softmax).
        _, predicted = torch.max(outputs, 1)                #- torch.max(outputs, 1) retorna o maior valor em cada linha (cada amostra), junto com o índice da classe correspondente.
        total += labels.size (0)                            #- labels.size(0): número de amostras no lote atual → soma ao total.
        correct += (predicted == labels).sum().item()       #- (predicted == labels): compara previsão com rótulo verdadeiro → retorna um tensor booleano. - .sum().item(): soma os acertos e converte para número → soma ao contador de acertos.


print(f'Acuracia no teste: {100 * correct / total:.2f}%')

"""
#Caso seja necessario uso de matriz de confusao

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in testloader:
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        all_preds.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Gera a matriz
cm = confusion_matrix(all_labels, all_preds)

# Visualiza com Seaborn
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title('Matriz de Confusão')
plt.show()

"""

"""
#teste com imagem

# 6. Testar com uma imagem do computador
from PIL import Image
import torchvision.transforms as transforms

# Carregar imagem (tem que estar na mesma pasta, ex: "meu_numero.png")
img = Image.open("meu_numero.png").convert("L")  # escala de cinza

# Transformar para o mesmo formato do MNIST
transform = transforms.Compose([
    transforms.Resize((28, 28)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

img_tensor = transform(img)
img_tensor = img_tensor.unsqueeze(0)  # adiciona dimensão batch [1, 1, 28, 28]

# Fazer previsão
model.eval()
with torch.no_grad():
    output = model(img_tensor)
    _, predicted = torch.max(output, 1)

print("O modelo acha que é o número:", predicted.item())

"""





